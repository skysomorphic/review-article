\newglossaryentry{weight}{
    name = weight,
    plural = weights,
    description = {Parameters that are direct coefficients to values in a model. Determines strength of connections between nodes in neural networks},
}

\newglossaryentry{bias}{
    name = bias,
    plural = biases,
    description = {Parameters that add/offset to values in a model. Adds to a value add a node in neural networks. Not to be confused with \textit{model bias}},
}

\newglossaryentry{model-bias}{
    name = model bias,
    description = {Inherent limitations of a model's performance to its architecture. Not to be confused with \textit{bias}},
}

\newglossaryentry{loss-function}{
    name = loss function,
    description = {Function defined to measure the performance of a model, lower is better},
}

\newglossaryentry{label}{
    name = label,
    plural = labels,
    description = {The identifiers attached to training data that function as an ``answer key'' for what it is supposed to be},
}

\newacronym{mse}{MSE}{mean square error}

\newglossaryentry{error-surface}{
    name = error surface,
    description = {The surface that a loss function plots in parameter space},
}

\newglossaryentry{hyperparameter}{
    name = hyperparameter,
    plural = hyperparameters,
    description = {Values that specify aspects of a model's inherent architecture or its learning},
}

\newacronym[plural=ANNs]{ann}{ANN}{artificial neural network}

\newacronym[plural=NNs]{nn}{NN}{neural network}


\newglossaryentry{node}{
    name = node,
    plural = nodes,
    description = {},
}

\newglossaryentry{activation-function}{
    name = activation function,
    plural = activation functions,
    description = {},
}

\newacronym{relu}{ReLU}{rectified linear unit}

\newglossaryentry{feature}{
    name = feature,
    plural = features,
    description = {},
}